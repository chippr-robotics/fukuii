sync {
  # Whether to enable fast-sync
  do-fast-sync = true
  # Whether to enable SNAP sync (takes priority over fast-sync if enabled)
  do-snap-sync = true

  # Circuit-breaker cool-off period for in-process fast-sync restarts.
  # This prevents rapid thrashing if fast sync keeps getting restarted.
  fast-sync-restart-cooloff = 10.minutes
  # SNAP sync configuration
  # SNAP sync is a state synchronization protocol that downloads account and storage ranges
  # without intermediate Merkle trie nodes, significantly reducing sync time and bandwidth.
  # See: https://github.com/ethereum/devp2p/blob/master/caps/snap.md
  snap-sync {
    # Enable SNAP sync (requires do-snap-sync = true)
    enabled = true
    # Number of blocks before the best block to use as pivot for SNAP sync
    # Core-geth uses 64 blocks (fsMinFullBlocks) as the minimum threshold
    # This allows SNAP sync to start much sooner after genesis
    # A higher offset provides more stability against chain reorgs
    # A lower offset reduces the catch-up time after SNAP sync completes
    # Changed from 1024 to 64 to match core-geth exactly (for SNAP sync only)
    # Note: Fast-sync has its own separate pivot-block-offset setting (32 blocks)
    pivot-block-offset = 64
    # Number of concurrent account range download tasks
    # Higher values increase throughput but may overwhelm peers
    # Recommended: 16 tasks (divides 256-bit address space into 16 ranges)
    account-concurrency = 16
    # Number of concurrent storage range download tasks
    # Storage downloads are typically less voluminous than accounts
    # Recommended: 8 tasks (balances throughput with peer load)
    storage-concurrency = 16
    # Maximum number of accounts to request storage for in a single batch
    # Batching reduces message overhead
    # Recommended: 8 accounts per batch
    storage-batch-size = 8
    # Maximum number of trie node paths to request in a single healing request
    # Healing requests are typically fewer and can be larger
    # Recommended: 16 paths per batch
    healing-batch-size = 16
    # Whether to validate state completeness before transitioning to regular sync
    # When enabled, walks the entire state trie to detect missing nodes
    # Recommended: true for production (ensures correctness)
    # Can be disabled for testing/debugging
    state-validation-enabled = true
    # Maximum number of retries for failed SNAP sync requests
    # Failed requests are retried with exponential backoff
    # Recommended: 3 retries
    max-retries = 3
    # Timeout for SNAP sync requests (GetAccountRange, GetStorageRanges, etc.)
    # Should be long enough to allow large responses to be transmitted
    # Recommended: 30 seconds (matches peer-response-timeout)
    timeout = 30 seconds
    # Maximum number of critical SNAP sync failures before fallback to fast sync
    # Critical failures include circuit breaker trips and state validation failures
    # Recommended: 5 failures (provides enough retries while preventing infinite loops)
    max-snap-sync-failures = 5
  }
  # Interval for updating peers during sync
  # Increased from 3s to 5s to reduce peer scanning overhead
  peers-scan-interval = 5.seconds
  # Duration for blacklisting a peer. Blacklisting reason include: invalid response from peer, response time-out, etc.
  # 0 value is a valid duration and it will disable blacklisting completely (which can be useful when all nodes are
  # are controlled by a single party, eg. private networks)
  # Reduced from 200s to 120s to allow faster retry of peers that may have had transient issues
  blacklist-duration = 120.seconds
  # Duration for high offense blacklisting of a peer. Blacklisting reason include: header validation failure.
  # Reduced from 240 minutes to 60 minutes - still a significant penalty but allows recovery
  critical-blacklist-duration = 60.minutes
  # Retry interval when not having enough peers to start fast-sync
  start-retry-interval = 5.seconds
  # Retry interval for resuming fast sync after all connections to peers were lost
  # Also retry interval in regular sync: for picking blocks batch and retrying requests
  sync-retry-interval = 0.5 seconds
  # Delay between finishing fast sync and starting regular sync
  sync-switch-delay = 0.5 seconds
  # Response time-out from peer during sync. If a peer fails to respond within this limit, it will be blacklisted
  # Increased from 30s to 45s to be more tolerant of network latency and peer load
  peer-response-timeout = 45.seconds
  # Interval for logging syncing status info
  print-status-interval = 30.seconds
  # How often to dump fast-sync status to disk. If the client is restarted, fast-sync will continue from this point
  persist-state-snapshot-interval = 1.minute
  # Maximum concurrent requests when in fast-sync mode
  max-concurrent-requests = 50
  # Requested number of block headers when syncing from other peers
  # Aligned with max-blocks-headers-per-message to request full batches
  # Pushed to safe maximum of 1024 headers for maximum sync throughput
  block-headers-per-request = 1024
  # Requested number of block bodies when syncing from other peers
  # Core Geth limits responses to 2MB, reduced from 100 to 50 to align with
  # max-blocks-bodies-per-message and stay reliably under 2MB soft limit
  block-bodies-per-request = 50
  # Max. number of blocks that are going to be imported in one batch
  blocks-batch-size = 50
  # Requested number of TX receipts when syncing from other peers
  # Aligned with max-receipts-per-message to request full batches
  # Pushed to safe maximum of 1024 receipts for maximum sync throughput
  receipts-per-request = 1024
  # Requested number of MPT nodes when syncing from other peers
  nodes-per-request = 384
  # Minimum number of peers required to start fast-sync (by determining the pivot block)
  min-peers-to-choose-pivot-block = 3
  # Number of additional peers used to determine pivot block during fast-sync
  # Number of peers used to reach consensus = min-peers-to-choose-pivot-block + peers-to-choose-pivot-block-margin
  peers-to-choose-pivot-block-margin = 3
  # Number of peers to fetch the blocks in parallel for execution sync
  peers-to-fetch-from = 5
  # During fast-sync when most up to date block is determined from peers, the actual target block number
  # will be decreased by this value
  pivot-block-offset = 32
  # How often to query peers for new blocks after the top of the chain has been reached
  check-for-new-block-interval = 10.seconds
  # size of the list that keeps track of peers that are failing to provide us with mpt node
  # we switch them to download only blockchain elements
  fastsync-block-chain-only-peers-pool = 100
  # time between 2 consecutive requests to peer when doing fast sync, this is to prevent flagging us as spammer
  fastsync-throttle = 0.1 seconds
  # When we receive a branch that is not rooted in our chain (we don't have a parent for the first header), it means
  # we found a fork. To resolve it, we need to query the same peer for previous headers, to find a common ancestor.
  branch-resolution-request-size = 30
  # threshold for storing non-main-chain blocks in queue.
  # if: current_best_block_number - block_number > max-queued-block-number-behind
  # then: the block will not be queued (such already queued blocks will be removed)
  max-queued-block-number-behind = 1000
  # threshold for storing non-main-chain blocks in queue.
  # if: block_number - current_best_block_number > max-queued-block-number-ahead
  # then: the block will not be queued (such already queued blocks will be removed)
  max-queued-block-number-ahead = 1000
  # Maximum number of blocks, after which block hash from NewBlockHashes packet is considered ancient
  # and peer sending it is blacklisted
  max-new-block-hash-age = 20
  # Maximum number of hashes processed form NewBlockHashes packet
  max-new-hashes = 64
  # This a recovery mechanism for the issue of missing state nodes during blocks execution:
  # off - missing state node will result in an exception
  # on - missing state node will be redownloaded from a peer and block execution will be retried. This can repeat
  #      several times until block execution succeeds
  redownload-missing-state-nodes = on
  # See: https://github.com/ethereum/go-ethereum/pull/1889
  fast-sync-block-validation-k = 100
  fast-sync-block-validation-n = 2048
  fast-sync-block-validation-x = 24
  # Maxium difference between our target block and best possible target block (current best known block - offset)
  # This is to ensure that we start downloading our state as close as possible to top of the chain
  max-target-difference = 10
  # Maxium number of failure to update target block, this could happen when target block, or x blocks  after target
  # fail validation. Or when we keep getting old block from the network.
  maximum-target-update-failures = 5
  # Sets max number of blocks that can be stored in queue to import on fetcher side
  # Warning! This setting affects ability to go back in case of branch resolution so it should not be too low
  max-fetcher-queue-size = 1000
  # Expected size fo state sync bloom filter.
  # Current Size of ETC state trie is aroud 150M Nodes, so 200M is set to have some reserve
  # If the number of elements inserted into bloom filter would be significally higher that expected, then number
  # of false positives would rise which would degrade performance of state sync
  state-sync-bloom-filter-size = 200000000
  # Max number of mpt nodes held in memory in state sync, before saving them into database
  # 100k is around 60mb (each key-value pair has around 600bytes)
  state-sync-persist-batch-size = 100000
  # If new pivot block received from network will be less than fast sync current pivot block, the re-try to chose new
  # pivot will be scheduler after this time. Avarage block time in etc/eth is around 15s so after this time, most of
  # network peers should have new best block
  pivot-block-reschedule-interval = 15.seconds
  # If for most network peers, the following condition will be true:
  # (peer.bestKnownBlock - pivot-block-offset) - node.curentPivotBlock > max-pivot-age
  # it fast sync pivot block has become stale and it needs update
  max-pivot-block-age = 96

  # Maximum total attempts performed by the pivot block selector before it gives up and reports failure.
  # This is a safety guard against infinite loops when no suitable peers are available.
  # Note: Fukuii will retry pivot selection after start-retry-interval, so this mainly controls how long
  # a single selection run should persist before restarting.
  pivot-block-max-total-selection-attempts = 20
  # Maximum number of retries performed by fast sync when the master peer sends invalid block headers.
  # On reaching this limit, it will perform branch resolving.
  fast-sync-max-batch-retries = 5
  # Max number of times a pivot block is checked against available best peers before the whole process is restarted.
  max-pivot-block-failures-count = 5
}